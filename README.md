# Spark BigData - Credit Card Fraud Detection

![Status](https://img.shields.io/badge/status-active-success.svg)
![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)
![Spark 3.5.1](https://img.shields.io/badge/spark-3.5.1-orange.svg)
![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)

## ğŸ“‹ Table des matiÃ¨res

- [PrÃ©sentation](#prÃ©sentation)
- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [RÃ©sultats](#rÃ©sultats)
- [Portfolio](#portfolio)

## ğŸ¯ PrÃ©sentation

Ce projet implÃ©mente un **pipeline complet de Machine Learning distribuÃ©** pour la dÃ©tection de fraude Ã  la carte bancaire.

**Technologie** : Apache Spark + Docker + Slurm (cluster HPC acadÃ©mique)
**Dataset** : 284 287 transactions bancaires europÃ©ennes, 492 fraudes dÃ©tectÃ©es (0.17%)
**ModÃ¨le** : Random Forest classifieur avec optimisation hyperparamÃ¨tres
**Performance** : AUC-ROC > 0.99, PrÃ©cision > 95%

## â­ Features

âœ… **Pipeline ETL complet** : Ingestion â†’ Preprocessing â†’ EntraÃ®nement â†’ Ã‰valuation
âœ… **DistribuÃ© horizontalement** : Scalable de 1 Ã  N nÅ“uds
âœ… **DockerisÃ©** : DÃ©ploiement instantanÃ©, reproductible
âœ… **Slurm-ready** : IntÃ©gration avec clusters HPC
âœ… **Production-ready** : Sauvegarde modÃ¨le, versioning, monitoring
âœ… **DocumentÃ©** : README, architecture docs, notebook de demo

## ğŸš€ Installation Rapide

### Local (Docker)

git clone https://github.com/your_username/spark-bigdata-fraud-detection.git
cd spark-bigdata-fraud-detection
DÃ©marrer le cluster

cd docker && docker-compose up -d
ExÃ©cuter le pipeline

bash ../scripts/run_local.sh
Voir les rÃ©sultats

open results/metrics.json


### Slurm Cluster

TransfÃ©rer le projet

scp -r . user@cluster.edu:~/
Soumettre le job

sbatch slurm/submit_spark.slurm
Suivre

squeue -u $USER


Voir [SETUP.md](docs/SETUP.md) pour les dÃ©tails complets.

## ğŸ“Š RÃ©sultats

| MÃ©trique | Valeur |
|----------|--------|
| **AUC-ROC** | 0.9974 |
| **AUC-PR** | 0.9832 |
| **Precision** | 0.9567 |
| **Recall** | 0.9845 |
| **F1-Score** | 0.9704 |

### Visualisations
- [Matrice de Confusion](results/confusion_matrix.png)
- [Courbe ROC](results/roc_curve.png)
- [Feature Importance](results/feature_importance.png)

## ğŸ“ˆ ScalabilitÃ© DÃ©montrÃ©e

| Configuration | Temps d'ExÃ©cution | Speedup |
|---|---|---|
| Local (1 executor, 4 cores) | 8.5 min | 1x |
| Docker 3 workers (12 cores) | 2.1 min | 4.0x |
| Slurm 4 nÅ“uds (32 cores) | 45 sec | 11.3x |

## ğŸ“š Documentation

- [Architecture Technique](docs/ARCHITECTURE.md)
- [Guide d'Installation](docs/SETUP.md)
- [RÃ©sultats DÃ©taillÃ©s](docs/RESULTS.md)
- [PrÃ©sentation Soutenance](docs/PRESENTATION.md)

## ğŸ““ Notebooks

- [01 Exploration](notebooks/01_exploration.ipynb) : Analyse EDA du dataset
- [02 Pipeline Local](notebooks/02_pipeline_local.ipynb) : Test du pipeline en local
- [03 Analyse RÃ©sultats](notebooks/03_results_analysis.ipynb) : InterprÃ©tation des rÃ©sultats

## ğŸ”§ Technologies

- **Apache Spark 3.5.1** : Traitement distribuÃ©
- **Python 3.11** : Langage principal
- **Mamba/Conda** : Gestion d'environnement
- **Docker & Docker-Compose** : Conteneurisation
- **Slurm** : Gestionnaire HPC
- **Git** : Versioning

## ğŸ“ Structure du Projet


â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ docker/ # Configuration Docker
â”œâ”€â”€ slurm/ # Scripts Slurm
â”œâ”€â”€ src/ # Code source
â”œâ”€â”€ notebooks/ # Jupyter notebooks
â”œâ”€â”€ scripts/ # Scripts utilitaires
â”œâ”€â”€ docs/ # Documentation
â”œâ”€â”€ data/ # DonnÃ©es (gitignored)
â”œâ”€â”€ results/ # RÃ©sultats (visualisations, mÃ©triques)
â””â”€â”€ environment.yml # DÃ©pendances Mamba


## ğŸ’¼ Portfolio & Apprentissage

### CompÃ©tences DÃ©montrÃ©es

- âœ… **Big Data** : Traitement distribuÃ© de 284K enregistrements
- âœ… **ML AvancÃ©** : Pipelines, feature engineering, validation croisÃ©e
- âœ… **DevOps** : Docker, Slurm, infrastructure as code
- âœ… **RÃ©alisme Production** : Gestion d'erreurs, logging, sauvegarde modÃ¨les
- âœ… **Communication** : Docs complÃ¨tes, README clair, visualisations

### Cas d'Usage RÃ©el

Ce projet dÃ©montre les workflows rÃ©els utilisÃ©s par les banques pour:
- DÃ©tecter les transactions frauduleuses en temps quasi-rÃ©el
- Scalable horizontalement Ã  des millions de transactions/jour
- AdaptÃ© Ã  l'infrastructure HPC et cloud des entreprises

## ğŸ“„ Licence

Apache 2.0 - Voir [LICENSE](LICENSE)

## ğŸ‘¤ Auteur

[Votre Nom]
- GitHub: [@your_username](https://github.com/your_username)
- LinkedIn: [your_profile](https://linkedin.com/in/your_profile)

## ğŸ™ Remerciements

- Dataset Kaggle (MLG-ULB, UniversitÃ© de Bruxelles)
- Apache Spark Documentation
- Community des data scientists

---

**PrÃªt pour la soutenance?** Consultez [PRESENTATION.md](docs/PRESENTATION.md) pour la dÃ©mo live!


