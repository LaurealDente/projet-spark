#!/bin/bash

# ===================================================================
# SCRIPT DE LANCEMENT DU PIPELINE EN MODE LOCAL NATIF (SANS DOCKER)
# ===================================================================

echo "ðŸš€ Lancement du pipeline Spark en mode local natif..."

# 1. Activer l'environnement Conda/Mamba
# Assurez-vous que le nom de l'environnement est correct
source /home/laureal/miniforge3/bin/activate spark-fraud-detection
if [ $? -ne 0 ]; then
    echo "âŒ Erreur: Impossible d'activer l'environnement Mamba 'spark-fraud-detection'."
    echo "   Veuillez vÃ©rifier qu'il est bien crÃ©Ã© avec 'mamba env create -f environment.yml'"
    exit 1
fi
echo "âœ“ Environnement 'spark-fraud-detection' activÃ©."

# 2. DÃ©finir la configuration Spark pour le mode local
# 'local[*]' dit Ã  Spark d'utiliser autant de threads que de cÅ“urs CPU disponibles.
export SPARK_MASTER="local[*]"
# On alloue une partie de la RAM de votre machine au driver Spark.
export SPARK_DRIVER_MEMORY="4g" 

export PYSPARK_SUBMIT_ARGS='--conf "spark.driver.extraJavaOptions=--add-opens=java.base/java.lang=ALL-UNNAMED" pyspark-shell'

echo "âœ“ Configuration Spark dÃ©finie pour le mode 'local[*]'"

# 3. Lancer le script Python du pipeline
# Le script 'fraud_detection_pipeline.py' lira les variables d'environnement
# pour configurer sa session Spark.
echo "â–¶ï¸  ExÃ©cution du script Python 'src/fraud_detection_pipeline.py'..."
python src/fraud_detection_pipeline.py

# VÃ©rifier le code de sortie du script Python
if [ $? -eq 0 ]; then
  echo "âœ… Pipeline terminÃ© avec succÃ¨s en mode local."
else
  echo "âŒ Le pipeline a Ã©chouÃ© en mode local." >&2
fi

unset PYSPARK_SUBMIT_ARGS

echo "ðŸ‘‹ Fin du script de lancement."
