#!/bin/bash

# ==============================================================================
# Script de D√©marrage pour les conteneurs Spark Master et Worker
# ==============================================================================

# Charge les variables d'environnement de Spark (SPARK_HOME, etc.)
. "/opt/spark/bin/load-spark-env.sh"

# ------------------------------------------------------------------------------
# Logique de D√©marrage en fonction du R√¥le du Conteneur
# ------------------------------------------------------------------------------

# V√©rifie la variable d'environnement SPARK_WORKLOAD, qui est d√©finie
# dans le fichier docker-compose.yml.
if [ "$SPARK_WORKLOAD" == "master" ]; then

  echo "üöÄ D√©marrage du conteneur en mode MASTER..."

  # Lance le processus Master de Spark.
  $SPARK_HOME/bin/spark-class org.apache.spark.deploy.master.Master \
    --ip $SPARK_MASTER_HOST \
    --port $SPARK_MASTER_PORT \
    --webui-port $SPARK_MASTER_WEBUI_PORT >> $SPARK_MASTER_LOG 2>&1

elif [ "$SPARK_WORKLOAD" == "worker" ]; then

  echo "‚öôÔ∏è D√©marrage du conteneur en mode WORKER..."
  echo "Connexion au master : $SPARK_MASTER"

  # Lance le processus Worker de Spark.
  $SPARK_HOME/bin/spark-class org.apache.spark.deploy.worker.Worker \
    --webui-port $SPARK_WORKER_WEBUI_PORT \
    $SPARK_MASTER >> $SPARK_WORKER_LOG 2>&1

elif [ "$SPARK_WORKLOAD" == "submit" ]; then

  echo "SUBMITTING SPARK JOB"
  spark-submit $@

else
  echo "‚ùå Type de workload non d√©fini : '$SPARK_WORKLOAD'. Doit √™tre 'master', 'worker' ou 'submit'."
  exit 1
fi
